{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date: 2020/02\n",
    "\n",
    "#### SUMMARY:\n",
    "\n",
    "- This notebook represents the project quality analysis of the date exposed right above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEAM:\n",
    "\n",
    "##### Semester: 2020/02\n",
    "##### Professor: Hilmer Neri\n",
    "\n",
    "##### Members:\n",
    "\n",
    "- Arthur Matos\n",
    "- Brian Pina\n",
    "- Gabriel Sabanai\n",
    "- Guilherme Marques\n",
    "- Luiz Henrique Zamprogno\n",
    "- Luiz Pettengill\n",
    "- Matheus Blanco\n",
    "- Pedro Féo\n",
    "- Saleh Kader\n",
    "- Victor Buendia\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# Deal with API request\n",
    "import urllib3\n",
    "from urllib3 import request\n",
    "\n",
    "# Deal with visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from random import randint\n",
    "from IPython.core.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_format ='retina'\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('darkgrid',\n",
    "              {'xtick.bottom' : True,\n",
    "               'ytick.left': True,\n",
    "               'grid.linestyle':'--',\n",
    "               'font.monospace': ['Computer Modern Typewriter'],\n",
    "               'axes.edgecolor' : 'white'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATAFRAME SETTINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SonarCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = [\n",
    "    'Eccoar_Complaint',\n",
    "    'eccoar_frontend',\n",
    "    'Eccoar_Gateway',\n",
    "    'Eccoar_Mailer',\n",
    "    'Eccoar_Reports',\n",
    "    'Eccoar_Users'\n",
    "]\n",
    "\n",
    "language = [['Eccoar_Complaint', 'ts'], \n",
    "            ['eccoar_frontend', 'ts'], \n",
    "            ['Eccoar_Gateway', 'ts'], \n",
    "            ['Eccoar_Mailer', 'ts'], \n",
    "            ['Eccoar_Reports', 'ts'], \n",
    "            ['Eccoar_Users', 'ts']]\n",
    "\n",
    "repos_language = {}\n",
    "\n",
    "for item in language:\n",
    "    repos_language[f\"{item[0]}\"] = item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Eccoar_Complaint': 'ts',\n",
       " 'eccoar_frontend': 'ts',\n",
       " 'Eccoar_Gateway': 'ts',\n",
       " 'Eccoar_Mailer': 'ts',\n",
       " 'Eccoar_Reports': 'ts',\n",
       " 'Eccoar_Users': 'ts'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Path to the folder with all your jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = glob('**/*.json') # add the path here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = glob('issues.json')\n",
    "sprints = glob('sprints.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json(json_path):\n",
    "    \n",
    "    with open(json_path) as json_file:\n",
    "        json_obj = json.load(json_file)\n",
    "        \n",
    "    return json_obj\n",
    "\n",
    "\n",
    "def create_base_component_df(json_list):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in json_list:\n",
    "\n",
    "        base_component = read_json(i)\n",
    "\n",
    "        base_component_data = base_component['baseComponent']['measures']\n",
    "\n",
    "        base_component_df = pd.DataFrame(base_component_data)\n",
    "\n",
    "        base_component_df['filename'] = os.path.basename(i)\n",
    "\n",
    "        df = df.append(base_component_df, ignore_index=True)\n",
    "        \n",
    "    aux_df = df['filename'].str.split(r\"fga-eps-mds-2020_2-(.*?)-(.*?).json\", expand=True)\n",
    "    \n",
    "    df['repository'] = aux_df[1]\n",
    "    \n",
    "    df['version'] = aux_df[2]\n",
    "    \n",
    "    df = df.sort_values(by=['repository', 'version'])\n",
    "        \n",
    "    return df\n",
    "\n",
    "def create_base_issue_df(json_list):\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for i in issue_list:\n",
    "        base_issue = read_json(i)\n",
    "        base_issue_data = base_issue['baseIssue']['TAGS']\n",
    "        base_issue_df = pd.DataFrame(base_issue_data)\n",
    "        base_issue_df['filename'] = os.path.basename(i)\n",
    "        df = df.append(base_issue_df, ignore_index=True)\n",
    "    return df, repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_issues = pd.DataFrame()\n",
    "all_issues = read_json(issues[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sprints = read_json(sprints[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create base component dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_component_df = create_base_component_df(jsons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_list = ['files',\n",
    "               'functions',\n",
    "               'complexity',\n",
    "               'comment_lines_density',\n",
    "               'duplicated_lines_density',\n",
    "               'coverage',\n",
    "               'ncloc',\n",
    "               'security_rating',\n",
    "               'tests',\n",
    "               'test_success_density',\n",
    "               'test_execution_time',\n",
    "               'reliability_rating']\n",
    "\n",
    "len(metric_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_per_file(json):\n",
    "    \n",
    "    file_json = []\n",
    "    \n",
    "    for component in json['components']:\n",
    "        if component['qualifier'] == 'FIL':\n",
    "            file_json.append(component)\n",
    "            \n",
    "    return file_json\n",
    "\n",
    "def generate_file_dataframe_per_release(metric_list, json, language_extension):\n",
    "    \n",
    "    df_columns = metric_list\n",
    "    df = pd.DataFrame(columns = df_columns)\n",
    "    \n",
    "    for file in json:\n",
    "        try:\n",
    "            if file['language'] == language_extension:\n",
    "                for measure in file['measures']:\n",
    "                    df.at[file['path'], measure['metric']] = measure['value']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    df.reset_index(inplace = True)\n",
    "    df = df.rename({'index': 'path'}, axis=1).drop(['files'], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_file_df(json_list):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for i in json_list:\n",
    "\n",
    "        file_component = read_json(i)\n",
    "        \n",
    "        file_component_data = metric_per_file(file_component)\n",
    "\n",
    "        file_component_df = generate_file_dataframe_per_release(metric_list, file_component_data, language_extension = 'ts')\n",
    "\n",
    "        file_component_df['filename'] = os.path.basename(i)\n",
    "\n",
    "        df = df.append(file_component_df, ignore_index=True)\n",
    "        \n",
    "    # replace TeamName by yours.    \n",
    "    aux_df = df['filename'].str.split(r\"fga-eps-mds-2020_2-(.*?)-(.*?).json\", expand=True)\n",
    "    \n",
    "    df['repository'] = aux_df[1]\n",
    "    \n",
    "    df['version'] = aux_df[2]\n",
    "    \n",
    "    df = df.sort_values(by=['repository', 'version'])\n",
    "\n",
    "    df.to_csv('result2.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_component_df = create_file_df(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_component_df['version'] = pd.to_datetime(file_component_df['version'], format=\"%d-%m-%Y-%H:%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_component_df = file_component_df.sort_values(by='version')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_component_df.to_excel('data/data.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Eccoar_Reports', 'Eccoar_Users', 'Eccoar_Mailer',\n",
       "       'eccoar_frontend', 'Eccoar_Gateway', 'Eccoar_Complaint'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_component_df.repository.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataframe per repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Eccoar_Complaint', 'eccoar_frontend', 'Eccoar_Gateway', 'Eccoar_Mailer', 'Eccoar_Reports', 'Eccoar_Users'])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repository_dataframes = {} \n",
    "\n",
    "for repository in repos:\n",
    "    df = file_component_df[file_component_df['repository'] == f\"{repository}\"]\n",
    "    df.name = f\"{repository}\"\n",
    "    repository_dataframes[f\"{repository}\"] = df\n",
    "    \n",
    "repository_dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eccoar_complaint_df = file_component_df[file_component_df['repository'] == 'Eccoar_Complaint']\n",
    "eccoar_gateway_df = file_component_df[file_component_df['repository'] == 'Eccoar_Gateway']\n",
    "eccoar_frontend_df = file_component_df[file_component_df['repository'] == 'eccoar_frontend']\n",
    "eccoar_reports_df = file_component_df[file_component_df['repository'] == 'Eccoar_Reports']\n",
    "eccoar_mailer_df = file_component_df[file_component_df['repository'] == 'Eccoar_Mailer']\n",
    "eccoar_users_df = file_component_df[file_component_df['repository'] == 'Eccoar_Users']\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metric calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMPLEXITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m1(df):\n",
    "    \n",
    "    density_non_complex_files = len(df[(df['complexity'].astype(float)/df['functions'].astype(float)) < 10])/len(df)\n",
    "    \n",
    "    return density_non_complex_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### COMMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m2(df):\n",
    "    \n",
    "    density_comment_files = len(df[(df['comment_lines_density'].astype(float) > 10) & (df['comment_lines_density'].astype(float) < 30)])/len(df)\n",
    "    \n",
    "    return density_comment_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DUPLICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m3(df):\n",
    "    \n",
    "    duplication = len(df[(df['duplicated_lines_density'].astype(float) < 5)])/len(df)\n",
    "    \n",
    "    return duplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NCLOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _ncloc(df):\n",
    "    ncloc = 0\n",
    "    for each in df['ncloc']:\n",
    "        ncloc += int(each)\n",
    "    \n",
    "    return ncloc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PRODUCTIVITY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RESOLVED ISSUES' THROUGHPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m7(number_of_issues_resolved, number_of_issues):\n",
    "    \n",
    "    resolved_issues_throughput = round((number_of_issues_resolved / number_of_issues) * 100, 2)\n",
    "    \n",
    "    return resolved_issues_throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ISSUE TYPE IN A TIMEFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density(issue, number_of_issues):\n",
    "    issue_density = round((issue / number_of_issues) * 100, 2)\n",
    "    return issue_density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m8(tag_dict, number_of_issues):\n",
    "    \n",
    "    issue_densities = {\n",
    "        \"hotfix\": [density(tag_dict[\"HOTFIX\"], number_of_issues)],\n",
    "        \"docs\": [density(tag_dict[\"DOCS\"], number_of_issues)],\n",
    "        \"feature\": [density(tag_dict[\"FEATURE\"], number_of_issues)],\n",
    "        \"arq\": [density(tag_dict[\"ARQ\"], number_of_issues)],\n",
    "        \"devops\": [density(tag_dict[\"DEVOPS\"], number_of_issues)],\n",
    "        \"analytics\": [density(tag_dict[\"ANALYTICS\"], number_of_issues)],\n",
    "        \"us\": [density(tag_dict[\"US\"], number_of_issues)],\n",
    "        \"easy\": [density(tag_dict[\"EASY\"], number_of_issues)],\n",
    "        \"medium\": [density(tag_dict[\"MEDIUM\"], number_of_issues)],\n",
    "        \"hard\": [density(tag_dict[\"HARD\"], number_of_issues)],\n",
    "        \"eps\": [density(tag_dict[\"EPS\"], number_of_issues)],\n",
    "        \"mds\": [density(tag_dict[\"MDS\"], number_of_issues)]\n",
    "    }\n",
    "\n",
    "    issue_densities = pd.DataFrame.from_dict(issue_densities).T.reset_index()\n",
    "    \n",
    "    issue_densities.columns = ['density' ,'percentage']\n",
    "    \n",
    "    return issue_densities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "issues = glob('issues.json')\n",
    "sprints = glob('sprints.json')\n",
    "all_issues = read_json(issues[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate M8 and Create CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_m8(all_issues):\n",
    "    for issue in all_issues:\n",
    "        df = m8(all_issues[issue]['TAGS'], NUMBER_OF_ISSUES)\n",
    "        df.to_csv(f'fga-eps-mds-2020-2-Eccoar-qualidade-total-processo-m8-{int(issue.split(\" \")[1])}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_m8(all_issues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUGS RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m9(tag_dict, number_of_issues):\n",
    "    \n",
    "    bugs_ratio = round(((tag_dict[\"DOCS\"] + tag_dict[\"FEATURE\"] + tag_dict[\"ARQ\"] + tag_dict[\"DEVOPS\"] + tag_dict[\"ANALYTICS\"]) / number_of_issues) * 100, 2)\n",
    "    \n",
    "    return bugs_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = {\n",
    "    'HOTFIX': 15,\n",
    "    'DOCS': 121,\n",
    "    'FEATURE': 32,\n",
    "    'ARQ': 15,\n",
    "    'DEVOPS': 12,\n",
    "    'ANALYTICS': 23,\n",
    "    'US': 19,\n",
    "    'EASY': 28,\n",
    "    'MEDIUM': 22,\n",
    "    'HARD': 7,\n",
    "    'EPS': 61,\n",
    "    'MDS': 41\n",
    "}\n",
    "NUMBER_OF_ISSUES_RESOLVED=201\n",
    "NUMBER_OF_ISSUES=236"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85.17"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m7(NUMBER_OF_ISSUES_RESOLVED, NUMBER_OF_ISSUES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>density</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hotfix</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>docs</td>\n",
       "      <td>51.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>feature</td>\n",
       "      <td>13.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>arq</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>devops</td>\n",
       "      <td>5.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>analytics</td>\n",
       "      <td>9.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>us</td>\n",
       "      <td>8.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>easy</td>\n",
       "      <td>11.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>medium</td>\n",
       "      <td>9.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hard</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>eps</td>\n",
       "      <td>25.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mds</td>\n",
       "      <td>17.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      density  percentage\n",
       "0      hotfix        6.36\n",
       "1        docs       51.27\n",
       "2     feature       13.56\n",
       "3         arq        6.36\n",
       "4      devops        5.08\n",
       "5   analytics        9.75\n",
       "6          us        8.05\n",
       "7        easy       11.86\n",
       "8      medium        9.32\n",
       "9        hard        2.97\n",
       "10        eps       25.85\n",
       "11        mds       17.37"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m8(TAGS, NUMBER_OF_ISSUES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.02"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m9(TAGS, NUMBER_OF_ISSUES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate m1, m2, m3, m7, m8, m9 for each repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metrics_df(df):\n",
    "    \n",
    "    version_vec = df['version'].unique()\n",
    "    \n",
    "    m1_list = []\n",
    "    m2_list = []\n",
    "    m3_list = []\n",
    "    repository_list = []\n",
    "    version_list = []\n",
    "    ncloc_list = []\n",
    "    \n",
    "    metrics_df = pd.DataFrame()\n",
    "    \n",
    "    for version in version_vec:\n",
    "\n",
    "        version_df = df[df['version'] == version]\n",
    "\n",
    "        m1_list.append(m1(version_df))\n",
    "        m2_list.append(m2(version_df))\n",
    "        m3_list.append(m3(version_df))\n",
    "        repository_list.append(version_df['repository'].iloc[0])\n",
    "        version_list.append(version)\n",
    "        ncloc_list.append(_ncloc(version_df))\n",
    "        \n",
    "    metrics_df = pd.DataFrame({'m1': m1_list,\n",
    "                               'm2': m2_list,\n",
    "                               'm3': m3_list,\n",
    "                               'repository': repository_list, \n",
    "                               'version': version_list,\n",
    "                               'ncloc': ncloc_list\n",
    "                              })\n",
    "    \n",
    "    metrics_df.to_csv('result.csv')\n",
    "        \n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_metrics = {}\n",
    "\n",
    "for repository, repo_df in repository_dataframes.items():   \n",
    "    metrics_df = create_metrics_df(repo_df)\n",
    "    metrics_df.name = f\"{repository}\"\n",
    "    repository_metrics[f\"{repository}\"] = metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(base_issue_data):\n",
    "    base_issue_m7 = []\n",
    "    base_issue_m9 = []\n",
    "    sprint_list = []\n",
    "    start_list = []\n",
    "    end_list = []\n",
    "\n",
    "    for issue in base_issue_data:\n",
    "        base_issue_m7.append(m7(base_issue_data[issue]['CLOSED_ISSUES'], NUMBER_OF_ISSUES))\n",
    "        base_issue_m9.append(m9(base_issue_data[issue]['TAGS'], NUMBER_OF_ISSUES))\n",
    "        sprint_list.append(int(issue.split(\" \")[1]))\n",
    "        start_list.append(all_sprints[issue]['start'])\n",
    "        end_list.append(all_sprints[issue]['end'])\n",
    "    df = pd.DataFrame({\n",
    "                       'm7': base_issue_m7, \n",
    "                       'm9': base_issue_m9, \n",
    "                       'sprints': sprint_list,\n",
    "                       'start_sprint': start_list,\n",
    "                       'end_sprint': end_list\n",
    "                    })\n",
    "    metrics_df.to_csv('fga-eps-mds-2020-2-Eccoar-qualidade-total-processo.csv')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_df = create_df(all_issues)\n",
    "issue_df['start_sprint'] = pd.to_datetime(issue_df['start_sprint'], format='%d/%m/%Y')\n",
    "issue_df['end_sprint'] = pd.to_datetime(issue_df['end_sprint'], format='%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccoar_gateway_metrics = create_metrics_df(eccoar_gateway_df)\n",
    "eccoar_complaint_metrics = create_metrics_df(eccoar_complaint_df)\n",
    "eccoar_frontend_metrics = create_metrics_df(eccoar_frontend_df)\n",
    "eccoar_mailer_metrics = create_metrics_df(eccoar_mailer_df)\n",
    "eccoar_reports_metrics = create_metrics_df(eccoar_reports_df)\n",
    "eccoar_users_metrics = create_metrics_df(eccoar_users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.concat([eccoar_gateway_metrics, eccoar_complaint_metrics, eccoar_frontend_metrics, eccoar_mailer_metrics, eccoar_reports_metrics, eccoar_users_metrics], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_m7_and_m9(metrics_df):\n",
    "\n",
    "    m7_list = []\n",
    "    m9_list = []\n",
    "\n",
    "    for _, release in metrics_df.iterrows():\n",
    "\n",
    "        curr_version = release['version']\n",
    "\n",
    "        for _, row in issue_df.iterrows():\n",
    "            if pd.Timestamp.to_numpy(row['start_sprint']) <= curr_version <= pd.Timestamp.to_numpy(row['end_sprint']):\n",
    "                m7_list.append(row['m7'])\n",
    "                m9_list.append(row['m9'])\n",
    "\n",
    "    m7_list = pd.DataFrame(m7_list, columns=['m7'])\n",
    "    m9_list = pd.DataFrame(m9_list, columns=['m9'])\n",
    "\n",
    "    metrics_df = pd.concat([metrics_df, m7_list], axis=1)\n",
    "    metrics_df = pd.concat([metrics_df, m9_list], axis=1)\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccoar_gateway_metrics = add_m7_and_m9(eccoar_gateway_metrics)\n",
    "eccoar_complaint_metrics = add_m7_and_m9(eccoar_complaint_metrics)\n",
    "eccoar_frontend_metrics = add_m7_and_m9(eccoar_frontend_metrics)\n",
    "eccoar_mailer_metrics = add_m7_and_m9(eccoar_mailer_metrics)\n",
    "eccoar_reports_metrics = add_m7_and_m9(eccoar_reports_metrics)\n",
    "eccoar_users_metrics = add_m7_and_m9(eccoar_users_metrics)\n",
    "all_metrics = add_m7_and_m9(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ac(df):\n",
    "    df['asc1'] = (df['m1'] + df['m2'] + df['m3']) / 3\n",
    "    df['ac1'] = df['asc1']\n",
    "    df['totalAC1'] = df['asc1']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ac2(issue_df):\n",
    "    aux_df = pd.DataFrame({\n",
    "        \"asc2\": [],\n",
    "        \"totalAC2\": []\n",
    "    })\n",
    "    aux_df['asc2'] = (issue_df['m7'] + issue_df['m9']) / 2\n",
    "    aux_df['totalAC2'] = aux_df['asc2']\n",
    "    return pd.concat([issue_df, aux_df], 1)\n",
    "\n",
    "issue_df_v2 = calculate_ac2(issue_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccoar_gateway_metrics = calculate_ac(eccoar_gateway_metrics)\n",
    "eccoar_complaint_metrics = calculate_ac(eccoar_complaint_metrics)\n",
    "eccoar_frontend_metrics = calculate_ac(eccoar_frontend_metrics)\n",
    "eccoar_mailer_metrics = calculate_ac(eccoar_mailer_metrics)\n",
    "eccoar_reports_metrics = calculate_ac(eccoar_reports_metrics)\n",
    "eccoar_users_metrics = calculate_ac(eccoar_users_metrics)\n",
    "all_metrics = calculate_ac(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "eccoar_gateway_metrics = calculate_ac2(eccoar_gateway_metrics)\n",
    "eccoar_complaint_metrics = calculate_ac2(eccoar_complaint_metrics)\n",
    "eccoar_frontend_metrics = calculate_ac2(eccoar_frontend_metrics)\n",
    "eccoar_mailer_metrics = calculate_ac2(eccoar_mailer_metrics)\n",
    "eccoar_reports_metrics = calculate_ac2(eccoar_reports_metrics)\n",
    "eccoar_users_metrics = calculate_ac2(eccoar_users_metrics)\n",
    "all_metrics = calculate_ac2(all_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_linear_regression(df):\n",
    "    sns.regplot(x=df[\"totalAC1\"], y=df[\"totalAC2\"], line_kws={\"color\":\"r\",\"alpha\":0.7,\"lw\":5})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive Statistic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Realizes the calculation of statistic data such as mean, median, mode, min, max, standard deviation and variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descriptive_statistics(df):\n",
    "    \n",
    "    metrics = df.describe()\n",
    "    variance = df.var()\n",
    "    variance_df = pd.DataFrame(variance, columns=[\"var\"])\n",
    "    variance_df = variance_df.T\n",
    "    return metrics.append(variance_df).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization\n",
    "\n",
    "- You must do this for each of your repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(df, repository):\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.title(f\"{repository}:COMPLEXITY\")\n",
    "    plt.plot(df['m1'], linewidth=3, marker='o', markersize=10)\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.title(f\"{repository}:COMMENTS\")\n",
    "    plt.plot(df['m2'], linewidth=3, marker='o', markersize=10)\n",
    "    fig = plt.figure(figsize=(20, 10))\n",
    "    plt.title(f\"{repository}:DUPLICATIONS\")\n",
    "    plt.plot(df['m3'], linewidth=3, marker='o', markersize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Repositories Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_histogram(repository, df):\n",
    "    fig = plt.figure(figsize=(30, 10))\n",
    "    plt.title(f\"{repository}:COMPLEXITY\")\n",
    "    plt.bar(df.index.values.tolist(), df['m1'], color='g')\n",
    "    plt.show()\n",
    "    plt.title(f\"{repository}:COMMENTS\")\n",
    "    plt.bar(df.index.values.tolist(), df['m2'], color='b')\n",
    "    plt.show()\n",
    "    plt.title(f\"{repository}:DUPLICATIONS\")\n",
    "    plt.bar(df.index.values.tolist(), df['m3'], color='red')\n",
    "    plt.show()\n",
    "    plt.title(f\"{repository}:MAINTAINABILITY\")\n",
    "    plt.bar(df.index.values.tolist(), df['asc1'], color='purple')\n",
    "    plt.show()\n",
    "    plt.title(f\"{repository}:PRODUCTIVITY\")\n",
    "    plt.bar(df.index.values.tolist(), df['asc2'], color='orange')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlationMatrix(df):\n",
    "    corrMatrix = df.corr()\n",
    "    return corrMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de correlação \n",
    "\n",
    "Ao fazermos uma análise de dado é importante criar uma matriz de correlação para que possamos associar os valores das váriaveis entre si. Dessa forma, uma matriz de correlação é o retorno de uma tabela com coeficientes que mostram a correlação de cada variavel.\n",
    "\n",
    "## Como interpretar o resultado\n",
    "\n",
    "O coeficiente da correlação vária de 1 e -1, sendo assim, respectivamente, positiva, negativa ou nula, tal que:\n",
    "\n",
    "* Correlação positiva: Ambas as variáveis mudam na mesma direção. Assim, ambas váriaveis correlacionadas se movem na mesma direção, logo se uma tem seu valor aumentado, a outra também.\n",
    "\n",
    "* Correlação Nula: Nenhuma relação na mudança das variáveis. Isso ocorre apenas se o coeficiente da correlação for 0.\n",
    "\n",
    "* Correlação negativa: As variáveis mudam em direções opostas. Dessa forma, se uma váriavel tem seu valor aumentado, a outra diminui seu valor. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame M1, M2, M3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_percentage_product = eccoar_complaint_metrics.to_html(formatters={\n",
    "    'm1': '{:.2}%'.format,\n",
    "    'm2': '{:.2}%'.format,\n",
    "    'm3': '{:.2}%'.format,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m1</th>\n",
       "      <th>m2</th>\n",
       "      <th>m3</th>\n",
       "      <th>repository</th>\n",
       "      <th>version</th>\n",
       "      <th>ncloc</th>\n",
       "      <th>m7</th>\n",
       "      <th>m9</th>\n",
       "      <th>asc1</th>\n",
       "      <th>ac1</th>\n",
       "      <th>totalAC1</th>\n",
       "      <th>asc2</th>\n",
       "      <th>totalAC2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.67%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-03-23</td>\n",
       "      <td>163</td>\n",
       "      <td>4.66</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>4.025</td>\n",
       "      <td>4.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.53%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-04-12</td>\n",
       "      <td>451</td>\n",
       "      <td>7.63</td>\n",
       "      <td>6.36</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>6.995</td>\n",
       "      <td>6.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.53%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-04-17</td>\n",
       "      <td>451</td>\n",
       "      <td>5.93</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>6.990</td>\n",
       "      <td>6.990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.59%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-04-21</td>\n",
       "      <td>565</td>\n",
       "      <td>4.66</td>\n",
       "      <td>5.08</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>4.870</td>\n",
       "      <td>4.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.56%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-04-27</td>\n",
       "      <td>587</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>4.870</td>\n",
       "      <td>4.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.58%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>626</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>4.870</td>\n",
       "      <td>4.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.58%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-05-03</td>\n",
       "      <td>626</td>\n",
       "      <td>5.08</td>\n",
       "      <td>4.66</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>4.870</td>\n",
       "      <td>4.870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.7%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-05-05</td>\n",
       "      <td>711</td>\n",
       "      <td>5.93</td>\n",
       "      <td>6.78</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>6.355</td>\n",
       "      <td>6.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.7%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>759</td>\n",
       "      <td>5.93</td>\n",
       "      <td>6.78</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>6.355</td>\n",
       "      <td>6.355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.67%</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>1.0%</td>\n",
       "      <td>Eccoar_Complaint</td>\n",
       "      <td>2021-05-17</td>\n",
       "      <td>832</td>\n",
       "      <td>5.51</td>\n",
       "      <td>5.93</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>5.720</td>\n",
       "      <td>5.720</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(descriptive_percentage_product))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_excel('data/metrics_df.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrame M7, M9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
